{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для \"Викишоп\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин \"Викишоп\" запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию\n",
    "\n",
    "Наша задача подобрать подходящую модель и обучить её классифицировать комментарии на позитивные и негативные (токсичные). В нашем распоряжении набор данных с разметкой о токсичности правок\n",
    "\n",
    "**Данные** находятся в файле `toxic_comments.csv`. Столбец `text` в нём содержит текст комментария, а `toxic` — целевой признак\n",
    "\n",
    "**Примечание**: значением метрики качества `F1` должно быть не меньше 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План действий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загрузить и подготовить данные\n",
    "2. Обучить разные модели, выбрать лучшую и протестировать её\n",
    "3. Сделать выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые для работы модули:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим необходимые для библиотеки `nltk` токенизаторы, разметчики, словари:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настроим параметры и функции вывода на экран:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройки вывода датафреймов\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отключаем предупреждения\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим жирный шрифт и цвет вывода при помощи ANSI escape sequences\n",
    "reset = '\\033[0m'\n",
    "bold = reset + '\\033[1m'\n",
    "color_bold = reset + '\\033[1;94m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция вывода цветного заголовка (bold, blue) с линиями сверху и снизу\n",
    "def head_print(text, linesize=None):\n",
    "    linesize = linesize or len(text)\n",
    "    line = '—' * linesize\n",
    "    print(color_bold + line)\n",
    "    print(text)\n",
    "    print(line + reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# константа для фиксации сидов (параметр random_state=RND)\n",
    "RND = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 1.1. Загрузка и изучение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные из файла в датафрейм `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл с данными \"\u001b[0m\u001b[1;94mtoxic_comments.csv\u001b[0m\" был найден и загружен по адресу:\n",
      "\u001b[0m\u001b[1;94m/datasets/toxic_comments.csv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "file_name = 'toxic_comments.csv'\n",
    "for path in ['', 'data/', 'datasets/', '/datasets/']:\n",
    "    if os.path.exists(path + file_name):\n",
    "        break\n",
    "else:\n",
    "    path = 'https://code.s3.yandex.net/datasets/'\n",
    "df = pd.read_csv(path + file_name)\n",
    "print(f'Файл с данными \"{color_bold + file_name + reset}\" был найден и загружен по адресу:')\n",
    "print(color_bold + path + file_name + reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем общую информацию о датафрейме `df`, изучим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1;94m——————————————————————————————————————————————————\n",
      "В датафрейме \"df\":    Строк: 159292    Столбцов: 3\n",
      "——————————————————————————————————————————————————\u001b[0m\n",
      "\u001b[0m\u001b[1;94m\n",
      "Первые и последние 5 строк:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  \\\n",
       "0                0   \n",
       "1                1   \n",
       "2                2   \n",
       "3                3   \n",
       "4                4   \n",
       "...            ...   \n",
       "159287      159446   \n",
       "159288      159447   \n",
       "159289      159448   \n",
       "159290      159449   \n",
       "159291      159450   \n",
       "\n",
       "                                                                                                                                                                                                           text  \\\n",
       "0       Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remo...   \n",
       "1                                                                                              D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2       Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about...   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tid...   \n",
       "4                                                                                                                                           You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "...                                                                                                                                                                                                         ...   \n",
       "159287  \":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - i...   \n",
       "159288                                                                                                    You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93   \n",
       "159289                                                                                                                      Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.   \n",
       "159290                                                                                     And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.   \n",
       "159291           \"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"   \n",
       "\n",
       "        toxic  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "159287      0  \n",
       "159288      0  \n",
       "159289      0  \n",
       "159290      0  \n",
       "159291      0  \n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0m\u001b[1;94mОбщая информация:\n",
      "\u001b[0m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      "\n",
      "\u001b[0m\u001b[1;94mКоличество пропусков: 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "head_print(f'В датафрейме \"df\":    Строк: {df.shape[0]}    Столбцов: {df.shape[1]}')\n",
    "print(color_bold + '\\nПервые и последние 5 строк:')\n",
    "display(df)\n",
    "print('\\n' + color_bold + 'Общая информация:\\n' + reset)\n",
    "print(df.info())\n",
    "print('\\n' + color_bold + f'Количество пропусков: {df.isna().sum().sum()}' + reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ИТАК, у нас имеется датафрейм `df` с 159292 строчками и 3 столбцами:\n",
    "- Пропусков в данных нет, тип данных правильный\n",
    "- Столбец `text` содержит тексты комментариев\n",
    "- Столбец `toxic` — целевой признак — определяет, токсичный комментарий, или нет, и может содержать только значения `1`, или `0`. Таким образом перед нами стоит задача бинарной классификации\n",
    "- Столбец `Unnamed: 0` — это старые индексы (видимо, сохранились с тех времён, когда в датасете было на 159 записей больше), можем его удалить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем столбец 'Unnamed: 0'\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 1.2. Очистка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в комментариях много \"мусора\" помимо английских слов — цифры, скобки, знаки препинания, символы переноса строки и т.п. Кроме того, в текстах много сокращённых форм глагола, таких как \"weren't\", \"don't\", \"I'm\", \"can't\" и т.п. Необходимо \"почистить\" комментарии, оставив в них только слова из английских символов и пробелы. Напишем для этого функцию и применим к столбцу с комментариями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция возвращает очищенный текст (только англ. символы и одиночные пробелы)\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    # замена n't\n",
    "    text = re.sub(r\"won't\", \"will not \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"ain't\", \"are not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    # замена 's\n",
    "    text = re.sub(r\"she's\", \"she is \", text)\n",
    "    text = re.sub(r\"he's\", \"he is \", text)\n",
    "    text = re.sub(r\"it's\", \"it is \", text)\n",
    "    text = re.sub(r\"that's\", \"that is \", text)\n",
    "    text = re.sub(r\"there's\", \"there is \", text)\n",
    "    text = re.sub(r\"how's\", \"how is \", text)\n",
    "    text = re.sub(r\"where's\", \"where is \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"who's\", \"who is \", text)\n",
    "    text = re.sub(r\"let's\", \"let us \", text)\n",
    "    text = re.sub(r\"'s\", \" \", text)\n",
    "    # замена остальных 'xx\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"'re\", \" are \", text)\n",
    "    text = re.sub(r\"'ve\", \" have \", text)\n",
    "    text = re.sub(r\"'d\", \" had \", text)\n",
    "    text = re.sub(r\"'ll\", \" will \", text)\n",
    "    # удаление всех не английских символов\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)   \n",
    "    # удаление лишних пробелов\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 s, sys: 116 ms, total: 9.12 s\n",
      "Wall time: 9.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем первые 5 комментариев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1;94m————————————————————————————————————————————————————————————————————————————————\n",
      "Тексты комментариев (первые 5):\n",
      "————————————————————————————————————————————————————————————————————————————————\u001b[0m\n",
      "\u001b[0m\u001b[1;94m0:\n",
      "\u001b[0mexplanation why the edits made under my username hardcore metallica fan were reverted they were not vandalisms just closure on some gas after i voted at new york dolls fac and please do not remove the template from the talk page since i am retired now\n",
      "\n",
      "\u001b[0m\u001b[1;94m1:\n",
      "\u001b[0md aww he matches this background colour i am seemingly stuck with thanks talk january utc\n",
      "\n",
      "\u001b[0m\u001b[1;94m2:\n",
      "\u001b[0mhey man i am really not trying to edit war it is just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info\n",
      "\n",
      "\u001b[0m\u001b[1;94m3:\n",
      "\u001b[0mmore i cannot make any real suggestions on improvement i wondered if the section statistics should be later on or a subsection of types of accidents i think the references may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know there appears to be a backlog on articles for review so i guess there may be a delay until a reviewer turns up it is listed in the relevant form eg wikipedia good article nominations transport\n",
      "\n",
      "\u001b[0m\u001b[1;94m4:\n",
      "\u001b[0myou sir are my hero any chance you remember what page that is on\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_comments(n=5):\n",
    "    head_print(f'Тексты комментариев (первые {n}):', 80)\n",
    "    for i in range(n):\n",
    "        print(color_bold + f\"{i}:\\n\" + reset + f\"{df['text'][i]}\\n\")\n",
    "\n",
    "\n",
    "show_comments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, тексты комментариев почищены"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 1.3. Лемматизация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь для дальнейшей работы нужно лемматизировать все тексты — то есть привести все слова в них к начальным формам — леммам. Для лемматизации английских текстов воспользуемся функцией `WordNetLemmatizer()` из модуля `nltk`. Эта функция позволяет лемматизировать различные части речи (существительные, глаголы, причастия, ...). Для этого нужно каждое слово \"пометить\" тегом, определяющим, к какой части речи оно относится. Напишем функцию определения части речи, функцию лемматизации текста и применим её к столбцу с комментариями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# функция возвращает POS (часть речи) из словаря по первой букве POS-тега\n",
    "def get_pos(word):\n",
    "    # первая (с индексом 0) буква POS-тэга в верхнем регистре\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    # словарь частей речи (POS), ключ: первая буква POS-тега\n",
    "    pos_dict = {\"N\": wordnet.NOUN,  # существительное 'n'\n",
    "                \"J\": wordnet.ADJ,   # прилагательное 'a'\n",
    "                \"V\": wordnet.VERB,  # глагол 'v'\n",
    "                \"R\": wordnet.ADV}   # наречие 'r'\n",
    "    return pos_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "# функция лемматизации текста\n",
    "def lemmatize_text(text):\n",
    "    text = [lemmatizer.lemmatize(word, get_pos(word)) for word in nltk.word_tokenize(text)]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 5s, sys: 1min 33s, total: 17min 38s\n",
      "Wall time: 17min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['text'] = df['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем результат, первые 5 комментариев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1;94m————————————————————————————————————————————————————————————————————————————————\n",
      "Тексты комментариев (первые 5):\n",
      "————————————————————————————————————————————————————————————————————————————————\u001b[0m\n",
      "\u001b[0m\u001b[1;94m0:\n",
      "\u001b[0mexplanation why the edits make under my username hardcore metallica fan be revert they be not vandalism just closure on some gas after i vote at new york doll fac and please do not remove the template from the talk page since i be retire now\n",
      "\n",
      "\u001b[0m\u001b[1;94m1:\n",
      "\u001b[0md aww he match this background colour i be seemingly stuck with thanks talk january utc\n",
      "\n",
      "\u001b[0m\u001b[1;94m2:\n",
      "\u001b[0mhey man i be really not try to edit war it be just that this guy be constantly remove relevant information and talk to me through edits instead of my talk page he seem to care more about the format than the actual info\n",
      "\n",
      "\u001b[0m\u001b[1;94m3:\n",
      "\u001b[0mmore i can not make any real suggestion on improvement i wonder if the section statistic should be later on or a subsection of type of accident i think the reference may need tidy so that they be all in the exact same format ie date format etc i can do that later on if no one else do first if you have any preference for format style on reference or want to do it yourself please let me know there appear to be a backlog on article for review so i guess there may be a delay until a reviewer turn up it be list in the relevant form eg wikipedia good article nomination transport\n",
      "\n",
      "\u001b[0m\u001b[1;94m4:\n",
      "\u001b[0myou sir be my hero any chance you remember what page that be on\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_comments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тексты комментариев лемматизированы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 1.4. Исследование баланса классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим отдельно фичи `X` и целевой признак, таргет `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['toxic'], axis=1)\n",
    "y = df['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь исследуем целевой признак на предмет баланса классов. Выведем распределение классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция вывода баланса классов для выборки (по умолчанию для исходного датасета)\n",
    "def get_ballance(data=y, subset='Исходный датасет'):\n",
    "    count = np.bincount(data)\n",
    "    head_print(f'{subset}:', 40)\n",
    "    print(color_bold + f'Всего значений   {len(data):<6}')\n",
    "    print(f'Из них: нулей    {count[0]:<6}  ({count[0] / len(data):.2%})')\n",
    "    print(f'        единиц   {count[1]:<6}  ({count[1] / len(data):.2%})')\n",
    "    print(reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1;94m————————————————————————————————————————\n",
      "Исходный датасет:\n",
      "————————————————————————————————————————\u001b[0m\n",
      "\u001b[0m\u001b[1;94mВсего значений   159292\n",
      "Из них: нулей    143106  (89.84%)\n",
      "        единиц   16186   (10.16%)\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "get_ballance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(np.bincount(y)).plot(kind='pie', label='', figsize=(3, 3), autopct='%1.1f%%')\n",
    "plt.title('Соотношение классов целевого признака')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдаем сильный дисбаланс классов — нулей примерно в девять раз больше, чем единиц. Необходимо будет учесть это при обучении моделей! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 1.5. Разделение данных на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные в соотношении 3:1 — 75% для обучающей выборки и 25% для тестовой. Учитывая дисбаланс классов, применим параметр `stratify` для сохранения соотношения нулей и единиц для всех выборок на том же уровне, что и в исходном целевом признаке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RND, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1;94mРазмер обучающей выборки    : 119469\n",
      "Размер тестовой выборки     : 39823 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(color_bold + 'Размер обучающей выборки    :', len(X_train))\n",
    "print('Размер тестовой выборки     :', len(X_test), reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что соотношение нулей и единиц во всех выборках совпадает с изначальным дисбалансом классов в датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1;94m————————————————————————————————————————\n",
      "Исходный датасет:\n",
      "————————————————————————————————————————\u001b[0m\n",
      "\u001b[0m\u001b[1;94mВсего значений   159292\n",
      "Из них: нулей    143106  (89.84%)\n",
      "        единиц   16186   (10.16%)\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[1;94m————————————————————————————————————————\n",
      "Обучающая выборка:\n",
      "————————————————————————————————————————\u001b[0m\n",
      "\u001b[0m\u001b[1;94mВсего значений   119469\n",
      "Из них: нулей    107330  (89.84%)\n",
      "        единиц   12139   (10.16%)\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[1;94m————————————————————————————————————————\n",
      "Тестовая выборка:\n",
      "————————————————————————————————————————\u001b[0m\n",
      "\u001b[0m\u001b[1;94mВсего значений   39823 \n",
      "Из них: нулей    35776   (89.84%)\n",
      "        единиц   4047    (10.16%)\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "get_ballance()\n",
    "get_ballance(y_train, 'Обучающая выборка')\n",
    "get_ballance(y_test, 'Тестовая выборка')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ИТАК, в ходе подготовки мы:\n",
    "- Загрузили и изучили данные\n",
    "- Провели первичную очистку текста (оставили только английские слова и пробелы)\n",
    "- Провели лемматизацию текста (привели все слова к начальным формам - леммам)\n",
    "- Исследовали баланс классов (обнаружен дисбаланс 9:1)\n",
    "- Разделили данные на обучающую и тестовую выборки\n",
    "\n",
    "Всё готово для обучения моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим функцию для вывода результатов подбора параметров моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_search_results(model, params, score):\n",
    "    head_print(f'Модель: {model}', 80)\n",
    "    print(color_bold + f'Лучшие параметры: {params}' + reset)\n",
    "    print(color_bold + f'F1 = {round(score, 3)}' + reset)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим разные модели. Будем использовать пайплайн, для того чтобы TF-IDF векторизатор внутри кросс-валидации обучался только на train-фолдах. Подберём гиперпараметры и выберем лучшую модель по метрике F1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 2.1. Модель LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры для наилучшей модели и рассчитаем метрику F1 на кросс-валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1;94m————————————————————————————————————————————————————————————————————————————————\n",
      "Модель: LogisticRegression\n",
      "————————————————————————————————————————————————————————————————————————————————\u001b[0m\n",
      "\u001b[0m\u001b[1;94mЛучшие параметры: {'model__C': 10, 'model__solver': 'lbfgs'}\u001b[0m\n",
      "\u001b[0m\u001b[1;94mF1 = 0.756\u001b[0m\n",
      "\n",
      "CPU times: user 2min 20s, sys: 2min 26s, total: 4min 47s\n",
      "Wall time: 4min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words=nltk_stopwords.words('english'))), \n",
    "                     ('model', LogisticRegression(class_weight='balanced'))])\n",
    "# params = {'model__solver': ['newton-cg', 'lbfgs', 'liblinear'], 'model__C': [0.1, 1, 10]}  # best: lbfgs, 10\n",
    "params = {'model__solver': ['lbfgs'], 'model__C': [10]}\n",
    "\n",
    "search = GridSearchCV(pipeline, params, scoring='f1', cv=5, n_jobs=-1)\n",
    "search.fit(X_train['text'], y_train)\n",
    "\n",
    "logit_score = search.best_score_\n",
    "logit_model = search.best_estimator_\n",
    "logit_params = search.best_params_\n",
    "\n",
    "show_search_results('LogisticRegression', logit_params, logit_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 2.2. Модель DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры для наилучшей модели и рассчитаем метрику F1 на кросс-валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1;94m————————————————————————————————————————————————————————————————————————————————\n",
      "Модель: DecisionTreeClassifier\n",
      "————————————————————————————————————————————————————————————————————————————————\u001b[0m\n",
      "\u001b[0m\u001b[1;94mЛучшие параметры: {'model__max_depth': 16}\u001b[0m\n",
      "\u001b[0m\u001b[1;94mF1 = 0.605\u001b[0m\n",
      "\n",
      "CPU times: user 1min 17s, sys: 482 ms, total: 1min 18s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words=nltk_stopwords.words('english'))), \n",
    "                     ('model', DecisionTreeClassifier(class_weight='balanced', random_state=RND))])\n",
    "# params = {'model__max_depth': range(9, 19)}  # best 16\n",
    "params = {'model__max_depth': [16]}\n",
    "\n",
    "search = GridSearchCV(pipeline, params, scoring='f1', cv=5, n_jobs=-1)\n",
    "search.fit(X_train['text'], y_train)\n",
    "\n",
    "dtc_score = search.best_score_\n",
    "dtc_model = search.best_estimator_\n",
    "dtc_params = search.best_params_\n",
    "\n",
    "show_search_results('DecisionTreeClassifier', dtc_params, dtc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 2.3. Модель CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры для наилучшей модели и рассчитаем метрику F1 на кросс-валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1;94m————————————————————————————————————————————————————————————————————————————————\n",
      "Модель: CatBoostClassifier\n",
      "————————————————————————————————————————————————————————————————————————————————\u001b[0m\n",
      "\u001b[0m\u001b[1;94mЛучшие параметры: {'model__max_depth': 5, 'model__n_estimators': 100}\u001b[0m\n",
      "\u001b[0m\u001b[1;94mF1 = 0.725\u001b[0m\n",
      "\n",
      "CPU times: user 14min 12s, sys: 9.68 s, total: 14min 21s\n",
      "Wall time: 14min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words=nltk_stopwords.words('english'))), \n",
    "                     ('model', CatBoostClassifier(auto_class_weights='Balanced', random_state=RND, verbose=0))])\n",
    "# params = {'model__max_depth': [3, 5, 7], 'model__n_estimators': [80, 100]}  # best 5, 100\n",
    "params = {'model__max_depth': [5], 'model__n_estimators': [100]}\n",
    "\n",
    "search = GridSearchCV(pipeline, params, scoring='f1', cv=5, n_jobs=-1)\n",
    "search.fit(X_train['text'], y_train)\n",
    "\n",
    "cbc_score = search.best_score_\n",
    "cbc_model = search.best_estimator_\n",
    "cbc_params = search.best_params_\n",
    "\n",
    "show_search_results('CatBoostClassifier', cbc_params, cbc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 2.4. Сравнение результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем результаты по всем моделям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1;94mЗначения метрики F1 для разных моделей\n",
      "(рассчитаны на кросс-валидации):\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           F1\n",
       "LogisticRegression      0.756\n",
       "DecisionTreeClassifier  0.605\n",
       "CatBoostClassifier      0.725"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_table = pd.DataFrame(data={'F1': [logit_score, dtc_score, cbc_score]}, \n",
    "                            index=['LogisticRegression', 'DecisionTreeClassifier', 'CatBoostClassifier'])\n",
    "result_table['F1'] = result_table['F1'].apply(lambda x: round(x, 3))\n",
    "\n",
    "print(color_bold + 'Значения метрики F1 для разных моделей\\n(рассчитаны на кросс-валидации):' + reset)\n",
    "display(result_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший результат показала модель логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 2.5. Тестирование лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем лучшую модель на тестовой выборке и рассчитаем метрику F1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1;94m————————————————————————————————————————————————————————————————————————————————\n",
      "Модель: LogisticRegression, проверка на тестовой выборке\n",
      "————————————————————————————————————————————————————————————————————————————————\u001b[0m\n",
      "\u001b[0m\u001b[1;94mF1 = 0.761\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pred_test = logit_model.predict(X_test['text'])\n",
    "score = f1_score(y_test, pred_test)\n",
    "\n",
    "head_print(f'Модель: LogisticRegression, проверка на тестовой выборке', 80)\n",
    "print(color_bold + f'F1 = {round(score, 3)}' + reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# 3. Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках данного проекта мы решали задачу бинарной классификации (определение токсичности комментариев пользователей Интернет-магазина заказчика). В ходе исследования:\n",
    "\n",
    "1. Подготовили данные\n",
    "    - Загрузили и изучили датасет с данными\n",
    "    - Провели первичную очистку и лемматизацию текста\n",
    "    - Разделили данные на обучающую и тестовую выборки с учетом выявленного дисбаланса классов\n",
    "\n",
    "\n",
    "3. Обучили разные модели с различными гиперпараметрами (используя pipeline)\n",
    "    - Рассмотрели 3 модели машинного обучения: `LogisticRegression`, `DecisionTreeClassifier`, `CatBoostClassifier`\n",
    "    - Векторизовали данные, создали матрицы признаков для моделей ML\n",
    "    - Оптимизировали качество моделей, меняя гиперпараметры, сравнив результаты по метрике F1, выбрали лучшую\n",
    "    - Проверили качество лучшей модели на тестовой выборке\n",
    "\n",
    "\n",
    "Лучшие результаты показала модель `LogisticRegression` с самой высокой метрикой F1 (0.756 на кросс-валидации и 0.761 на тестовой выборке). Также это оказалась единственная модель, соответствующая условиям проекта (F1 > 0.75). Таким образом, мы можем использовать данную модель машинного обучения в рамках задачи заказчика для классификации комментариев на положительные и отрицательные"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
